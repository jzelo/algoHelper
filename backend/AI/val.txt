Question: What is the time complexity of quicksort?
Answer: The average-case time complexity of quicksort is O(n log n). The worst-case time complexity is O(n^2) when the pivot selection is poor, but with good pivot selection, it remains O(n log n).

Question: How does merge sort work?
Answer: Merge sort is a divide-and-conquer algorithm that works by splitting an array into two halves, sorting the two halves, and then merging them back together. The merge operation combines two sorted arrays into a single sorted array.

Question: Explain bubble sort.
Answer: Bubble sort is a simple sorting algorithm that repeatedly steps through the list, compares adjacent elements and swaps them if they are in the wrong order. This process is repeated until the list is sorted. Its average and worst-case time complexity is O(n^2).

Question: Describe the steps of insertion sort.
Answer: Insertion sort builds the final sorted array one item at a time. It iterates through the input elements and grows the sorted array behind it. At each iteration, it removes one element from the input data, finds the location it belongs within the sorted list, and inserts it there. It continues until no input elements remain. The average and worst-case time complexity is O(n^2).

Question: What is quicksort?
Answer: Quicksort is a highly efficient sorting algorithm that uses a divide-and-conquer approach. It works by selecting a 'pivot' element from the array and partitioning the other elements into two sub-arrays, according to whether they are less than or greater than the pivot. The sub-arrays are then sorted recursively. This process results in a sorted array.

Question: What are the steps of quicksort?
Answer: The steps of quicksort are as follows:
1. Choose a pivot element from the array.
2. Partition the array into two sub-arrays: elements less than the pivot and elements greater than the pivot.
3. Recursively apply quicksort to the sub-arrays.
4. Combine the sub-arrays and the pivot into a sorted array.

Question: What is the time complexity of merge sort and why?
Answer: Merge sort has a time complexity of O(n log n). It divides the input array into two halves, calls itself for the two halves, and then merges the two sorted halves. The merge operation takes linear time, and the division takes logarithmic time, resulting in O(n log n) time complexity.

Question: Can you explain the merge process in merge sort?
Answer: The merge process in merge sort involves combining two sorted arrays into one sorted array. It works as follows:
1. Compare the first elements of both arrays.
2. Add the smaller element to the result array.
3. Move the pointer of the array from which the smaller element was taken.
4. Repeat steps 1-3 until all elements are added to the result array.

Question: What is insertion sort?
Answer: Insertion sort is a simple sorting algorithm that builds the final sorted array one item at a time. It works similarly to the way you sort playing cards in your hands. The array is virtually split into a sorted and an unsorted part. Values from the unsorted part are picked and placed at the correct position in the sorted part.

Question: How does bubble sort work?
Answer: Bubble sort works by repeatedly stepping through the list, comparing adjacent elements, and swapping them if they are in the wrong order. This process is repeated until no more swaps are needed, indicating that the list is sorted. The algorithm gets its name because smaller elements "bubble" to the top of the list.

Question: What are the advantages and disadvantages of bubble sort?
Answer: Advantages of bubble sort include its simplicity and ease of implementation. It is also useful for small datasets. However, it is inefficient for large datasets due to its O(n^2) time complexity, making it much slower compared to other sorting algorithms like quicksort and merge sort.

Question: What is heap sort and how does it work?
Answer: Heap sort is a comparison-based sorting technique based on a binary heap data structure. It works as follows:
1. Build a max heap from the input data.
2. At this point, the largest item is stored at the root of the heap. Replace it with the last item of the heap followed by reducing the size of the heap by one.
3. Heapify the root of the tree.
4. Repeat the above steps until the size of the heap is reduced to one.

Question: How does selection sort work?
Answer: Selection sort works by repeatedly finding the minimum element from the unsorted part and putting it at the beginning. The algorithm maintains two subarrays in a given array:
1. The subarray which is already sorted.
2. The remaining subarray which is unsorted.
In every iteration, the minimum element from the unsorted subarray is picked and moved to the sorted subarray.

Question: What is the difference between quicksort and merge sort?
Answer: Quicksort and merge sort both use divide-and-conquer strategies, but they differ in their approaches:
1. Quicksort: Divides the array into sub-arrays based on a pivot element and sorts the sub-arrays in-place. It generally performs faster but can degrade to O(n^2) time complexity if the pivot selection is poor.
2. Merge sort: Divides the array into two halves, sorts them, and merges them back together. It has a consistent O(n log n) time complexity and is stable, but it requires additional space for the temporary arrays used in the merge process.

Question: Can you give an example of how insertion sort works?
Answer: Sure, let's sort the array [12, 11, 13, 5, 6] using insertion sort:
1. Start with the first element 12. It is already sorted.
2. Move to the next element 11. Since 11 < 12, swap them. The array becomes [11, 12, 13, 5, 6].
3. Move to the next element 13. Since 13 > 12, no swap is needed. The array remains [11, 12, 13, 5, 6].
4. Move to the next element 5. Since 5 < 13, swap them. Now 5 < 12, swap again. Finally, 5 < 11, swap once more. The array becomes [5, 11, 12, 13, 6].
5. Move to the last element 6. Since 6 < 13, swap them. Now 6 < 12, swap again. Finally, 6 < 11, swap once more. The array becomes [5, 6, 11, 12, 13].
The array is now sorted.